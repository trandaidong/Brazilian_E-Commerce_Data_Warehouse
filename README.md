# Brazilian E-Commerce Data Warehouse
Build an exciting ELT data pipeline project focused on eCommerce data! This end-to-end pipeline extracts sales data, stages it for further analysis, and transforms it into actionable insights in a data warehouse.

Python and custom scripts were used to extract and load eCommerce data efficiently from CSV files and MySQL databases. PostgreSQL served as the staging area and the final data warehouse, handling structured sales data. Apache Airflow orchestrated the entire workflow, ensuring smooth operations from extraction to transformation. Containerized the project using Docker for seamless environment management and consistent deployment. Power BI provided the final layer of visualization, offering insightful sales analytics and business intelligence.
<img width="810" height="488" alt="image" src="https://github.com/user-attachments/assets/294470ce-000a-4f9a-87fa-85c32e2674e2" />
# Dataset
The project uses the Brazilian E-Commerce Public Dataset by Olist, a real-world dataset available on Kaggle. It contains about 100,000 orders placed on multiple Brazilian marketplaces from 2016 to 2018, organized into several CSV files. These tables include detailed information on orders, order items, products, payments, customer demographics (anonymized), sellers, reviews, and geolocation data. The datasetâ€™s rich, relational structure makes it ideal for building a data warehouse and demonstrating an end-to-end ELT pipeline with meaningful sales and customer analytics.
<img width="2486" height="1496" alt="image" src="https://github.com/user-attachments/assets/71bb2315-8f05-4360-9bff-5b00fd6090a6" />

